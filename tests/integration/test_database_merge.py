"""
Simplified database merge integration test that avoids relative import issues.
Tests merging two databases with different subsets of data through CSV export/import.
"""

import os
import sys
import tempfile
import shutil
import csv
from pathlib import Path

# Add the src directory to the path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

# Import only the database module to avoid relative import issues
from database.sqlite_database import SQLiteConferenceTalksDB


class SimpleDatabaseMergeTest:
    """Simplified database merge test that avoids problematic imports."""
    
    def __init__(self):
        self.test_dir = None
        self.db1_path = None
        self.db2_path = None
        self.merged_db_path = None
        self.dummy_data_path = None
        
    def setup(self):
        """Set up test environment."""
        print("üîß Setting up database merge test environment...")
        
        # Create temporary directory
        self.test_dir = tempfile.mkdtemp(prefix="database_merge_test_")
        print(f"  Created test directory: {self.test_dir}")
        
        # Set up database paths
        self.db1_path = os.path.join(self.test_dir, "database1.db")
        self.db2_path = os.path.join(self.test_dir, "database2.db")
        self.merged_db_path = os.path.join(self.test_dir, "merged_database.db")
        
        # Set up dummy data path
        self.dummy_data_path = project_root / "tests" / "dummy_data" / "General_Conference_Talks"
        
        if not self.dummy_data_path.exists():
            raise FileNotFoundError(f"Dummy data not found at: {self.dummy_data_path}")
            
        print(f"  Using dummy data from: {self.dummy_data_path}")
        
    def teardown(self):
        """Clean up test environment."""
        print("üßπ Cleaning up test environment...")
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
            print(f"  Removed test directory: {self.test_dir}")
            
    def get_available_years(self):
        """Get available years from dummy data."""
        years = []
        for year_dir in self.dummy_data_path.iterdir():
            if year_dir.is_dir() and year_dir.name.isdigit():
                years.append(year_dir.name)
        return sorted(years)
        
    def create_database_with_year_subset(self, db_path, years, keywords):
        """Create database with talks from specific years containing keywords."""
        print(f"  üì• Creating database with years: {years}")
        
        db = SQLiteConferenceTalksDB({'db_path': db_path})
        talks_added = 0
        paragraphs_added = 0
        
        for year in years:
            year_dir = self.dummy_data_path / year
            if not year_dir.exists():
                continue
                
            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir():
                    continue
                    
                month = month_dir.name
                session = "April" if month == "04" else "October"
                conference_date = f"{year}-{month}"
                
                for talk_file in month_dir.glob("*.txt"):
                    try:
                        with open(talk_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # Parse talk content
                        lines = content.split('\n')
                        title = speaker = url = talk_text = ""
                        
                        for i, line in enumerate(lines):
                            if line.startswith("Title: "):
                                title = line[7:].strip()
                            elif line.startswith("Speaker: "):
                                speaker = line[9:].strip()
                            elif line.startswith("URL: "):
                                url = line[5:].strip()
                            elif line.strip() == "" and i > 2:
                                talk_text = '\n'.join(lines[i+1:]).strip()
                                break
                        
                        if title and speaker and talk_text:
                            # Check if talk contains keywords
                            talk_text_lower = talk_text.lower()
                            found_keywords = [kw for kw in keywords if kw.lower() in talk_text_lower]
                            
                            if found_keywords:
                                # Add talk to database - use proper conference date format
                                conference_date = f"{session} {year}"
                                talk_id = db.add_talk(title, speaker, conference_date, url)
                                talks_added += 1
                                
                                # Add paragraphs containing keywords
                                paragraphs = [p.strip() for p in talk_text.split('\n\n') if p.strip()]
                                for i, paragraph in enumerate(paragraphs):
                                    if paragraph:
                                        paragraph_lower = paragraph.lower()
                                        paragraph_keywords = [kw for kw in keywords if kw.lower() in paragraph_lower]
                                        
                                        if paragraph_keywords:
                                            db.add_paragraph(talk_id, i + 1, paragraph, paragraph_keywords)
                                            paragraphs_added += 1
                                            
                    except Exception as e:
                        print(f"    ‚ùå Error processing {talk_file}: {e}")
        
        # Add keywords to database
        db.add_keywords(keywords)
        
        print(f"    ‚úÖ Database created with {talks_added} talks and {paragraphs_added} paragraphs")
        return db, talks_added, paragraphs_added
        
    def simple_csv_export(self, db, prefix):
        """Simple CSV export for testing."""
        print(f"  üì§ Exporting database to CSV: {prefix}")
        
        # Export talks
        talks_file = f"{prefix}_talks.csv"
        talks = db.get_talks_summary()
        
        with open(talks_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'title', 'speaker', 'conference_date', 'hyperlink'])
            for talk in talks:
                writer.writerow([
                    talk['id'], talk['title'], talk['speaker'], 
                    talk['conference_date'], talk.get('hyperlink', '')
                ])
        
        # Export paragraphs
        paragraphs_file = f"{prefix}_paragraphs.csv"
        paragraphs = db.get_all_paragraphs_with_filters()
        
        with open(paragraphs_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'talk_id', 'paragraph_number', 'content', 'matched_keywords'])
            for paragraph in paragraphs:
                writer.writerow([
                    paragraph['id'], paragraph['talk_id'], paragraph['paragraph_number'],
                    paragraph['content'], ','.join(paragraph.get('matched_keywords', []))
                ])
        
        # Export tags
        tags_file = f"{prefix}_tags.csv"
        tags = db.get_all_tags()
        
        with open(tags_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'name', 'description'])
            for tag in tags:
                writer.writerow([tag['id'], tag['name'], tag.get('description', '')])
        
        print(f"    ‚úÖ Exported {len(talks)} talks, {len(paragraphs)} paragraphs, {len(tags)} tags")
        return {'talks': talks_file, 'paragraphs': paragraphs_file, 'tags': tags_file}
        
    def simple_csv_import(self, db, csv_files):
        """Simple CSV import for testing."""
        print(f"  üì• Importing CSV files into database")
        
        # Import talks
        if os.path.exists(csv_files['talks']):
            with open(csv_files['talks'], 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        db.add_talk(
                            row['title'], row['speaker'], row['conference_date'],
                            row['hyperlink']
                        )
                    except Exception:
                        pass  # Talk might already exist
        
        # Import paragraphs
        if os.path.exists(csv_files['paragraphs']):
            with open(csv_files['paragraphs'], 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        keywords = row['matched_keywords'].split(',') if row['matched_keywords'] else []
                        db.add_paragraph(
                            int(row['talk_id']), int(row['paragraph_number']),
                            row['content'], keywords
                        )
                    except Exception:
                        pass  # Paragraph might already exist
        
        # Import tags
        if os.path.exists(csv_files['tags']):
            with open(csv_files['tags'], 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        db.add_tag(row['name'], row['description'])
                    except Exception:
                        pass  # Tag might already exist
        
        print(f"    ‚úÖ Import completed")
        
    def test_database_merge_workflow(self):
        """Test the database merge workflow."""
        print("\nüîÑ Testing database merge workflow...")
        
        # Get available years and split them
        years = self.get_available_years()
        if len(years) < 2:
            raise Exception("Need at least 2 years of dummy data for merge test")
        
        mid_point = len(years) // 2
        subset1_years = years[:mid_point]
        subset2_years = years[mid_point:]
        
        print(f"  üìä Subset 1 years: {subset1_years}")
        print(f"  üìä Subset 2 years: {subset2_years}")
        
        # Test keywords
        test_keywords = ["faith", "Christ"]
        
        # Create first database with subset 1
        print("\nüìä Creating Database 1:")
        db1, talks1, paragraphs1 = self.create_database_with_year_subset(
            self.db1_path, subset1_years, test_keywords
        )
        
        # Add a unique tag to database 1
        tag1_id = db1.add_tag("Database1Tag", "Tag from first database")
        
        # Create second database with subset 2
        print("\nüìä Creating Database 2:")
        db2, talks2, paragraphs2 = self.create_database_with_year_subset(
            self.db2_path, subset2_years, test_keywords
        )
        
        # Add a unique tag to database 2
        tag2_id = db2.add_tag("Database2Tag", "Tag from second database")
        
        # Export both databases
        print("\nüì§ Exporting databases:")
        csv_files1 = self.simple_csv_export(db1, os.path.join(self.test_dir, "export1"))
        csv_files2 = self.simple_csv_export(db2, os.path.join(self.test_dir, "export2"))
        
        # Create merged database
        print("\nüì• Creating merged database:")
        merged_db = SQLiteConferenceTalksDB({'db_path': self.merged_db_path})
        
        # Import both CSV sets
        self.simple_csv_import(merged_db, csv_files1)
        self.simple_csv_import(merged_db, csv_files2)
        
        # Verify merge results
        print("\n‚úÖ Verifying merge results:")
        merged_talks = merged_db.get_talks_summary()
        merged_paragraphs = merged_db.get_all_paragraphs_with_filters()
        merged_tags = merged_db.get_all_tags()
        
        print(f"  üìä Original DB1: {talks1} talks, {paragraphs1} paragraphs")
        print(f"  üìä Original DB2: {talks2} talks, {paragraphs2} paragraphs")
        print(f"  üìä Merged DB: {len(merged_talks)} talks, {len(merged_paragraphs)} paragraphs")
        print(f"  üìä Merged tags: {len(merged_tags)} tags")
        
        # Verify that merged database contains data from both sources
        tag_names = [tag['name'] for tag in merged_tags]
        
        success_conditions = [
            len(merged_talks) >= max(talks1, talks2),  # At least as many as larger DB
            len(merged_paragraphs) >= max(paragraphs1, paragraphs2),  # At least as many as larger DB
            "Database1Tag" in tag_names,  # Tag from DB1 preserved
            "Database2Tag" in tag_names,  # Tag from DB2 preserved
        ]
        
        all_success = all(success_conditions)
        
        if all_success:
            print("  ‚úÖ Merge verification successful!")
            print("  ‚úÖ Both databases merged correctly")
            print("  ‚úÖ Unique tags preserved from both databases")
            print("  ‚úÖ Data integrity maintained")
        else:
            print("  ‚ùå Merge verification failed!")
            print(f"  ‚ùå Success conditions: {success_conditions}")
            
        return all_success
        
    def run_test(self):
        """Run the database merge integration test."""
        print("üöÄ Starting Database Merge Integration Test")
        print("=" * 60)
        
        try:
            self.setup()
            success = self.test_database_merge_workflow()
            
            print("\n" + "=" * 60)
            if success:
                print("üéâ DATABASE MERGE INTEGRATION TEST PASSED!")
                print("‚úÖ Two databases with different data subsets merged successfully")
                print("‚úÖ CSV export/import workflow working correctly")
                print("‚úÖ Data integrity maintained during merge process")
            else:
                print("‚ùå DATABASE MERGE INTEGRATION TEST FAILED!")
                
            return success
            
        except Exception as e:
            print(f"\n‚ùå DATABASE MERGE INTEGRATION TEST FAILED WITH ERROR: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
            
        finally:
            self.teardown()


def main():
    """Main function to run the database merge integration test."""
    test = SimpleDatabaseMergeTest()
    success = test.run_test()
    
    if success:
        print("\nüéä Database merge integration test passed!")
        return 0
    else:
        print("\nüí• Database merge integration test failed!")
        return 1


if __name__ == "__main__":
    sys.exit(main())